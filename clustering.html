<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Understanding Clustering in Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="clustering_files/libs/clipboard/clipboard.min.js"></script>
<script src="clustering_files/libs/quarto-html/quarto.js"></script>
<script src="clustering_files/libs/quarto-html/popper.min.js"></script>
<script src="clustering_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="clustering_files/libs/quarto-html/anchor.min.js"></script>
<link href="clustering_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="clustering_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="clustering_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="clustering_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="clustering_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Understanding Clustering in Machine Learning</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Machine learning provides powerful techniques for uncovering patterns and structures within data. Clustering is an unsupervised learning, that is essential for grouping simlar data points. It has a lot of applications in many fields like image analysis, market segmentation, pattern recognition, social network analysis, etc., Many industries like airlines and healthcare use clustering.</p>
<p>This is a kind of unsupervised learning, that do not need labeled data, which is one of the biggest advantages over supervised learning like Classification. In this blog, we will cover the following topics:</p>
<ul>
<li>What is Clustering?</li>
<li>Types of Clustering</li>
</ul>
<ol type="1">
<li>Connectivity-based Clustering (Hierarchical Clustering)</li>
</ol>
<ul>
<li>Essential Clustering Algorithms</li>
</ul>
<section id="what-is-clustering" class="level2">
<h2 class="anchored" data-anchor-id="what-is-clustering">What is Clustering?</h2>
<p>Clustering is the process of grouping data points into clusters, where the data in a cluster are similar to each other. This is helpful in identifying patterns, compress large datasets and detect anomalies. In the Exploratory Data Analysis phase, Clustering is often used to discover new information and patterns in the data as clustering uses unlabeled dataset.</p>
<p>Clustering is a broad task encompassing diverse algorithms with distinct approaches to identify and define clusters within data efficiently. These algorithms vary in their interpretations of clusters and methodologies for their identification.</p>
</section>
<section id="types-of-clustering" class="level2">
<h2 class="anchored" data-anchor-id="types-of-clustering">Types of Clustering</h2>
<section id="connectivity-based-clustering-hierarchical-clustering" class="level3">
<h3 class="anchored" data-anchor-id="connectivity-based-clustering-hierarchical-clustering">Connectivity-based Clustering (Hierarchical Clustering)</h3>
<p>Hierarchical clustering, also known as connectivity-based clustering, organizes data points into a tree-like hierarchy. This measures similarity between clusters based on connectivity. There are two main types: Agglomerative (bottom-up) and Divisive (top-down).</p>
<ul>
<li>Agglomerative: Starts with individual data points as clusters and progressively merges them.</li>
<li>Divisive: Begins with one cluster containing all data points and iteratively splits them.</li>
</ul>
</section>
<section id="centroids-based-clustering-partitioning-methods" class="level3">
<h3 class="anchored" data-anchor-id="centroids-based-clustering-partitioning-methods">Centroids-based Clustering (Partitioning methods)</h3>
<p>Centroids-based clustering divides data into distinct partitions or clusters. Each cluster is represented by a centroid. The commonly used partitioning method is K-Means Clustering.</p>
<ul>
<li>K-Means: Minimizes variance within clusters by iteratively updating cluster centroids.</li>
</ul>
</section>
<section id="distribution-based-clustering" class="level3">
<h3 class="anchored" data-anchor-id="distribution-based-clustering">Distribution-based Clustering</h3>
<p>Distribution-based clustering assumes data points are generated from underlying probability distributions. The common distribution based method is Gaussian Mixture Models (GMM).</p>
<ul>
<li>GMM: Represents data as a mixture of Gaussian distributions, accommodating complex cluster shapes.</li>
</ul>
</section>
<section id="density-based-clustering-model-based-methods" class="level3">
<h3 class="anchored" data-anchor-id="density-based-clustering-model-based-methods">Density-based Clustering (Model-based methods)</h3>
<p>Desity-based clustering forms clusters based on the density of data points. This doesn’t require specifying the number of clusters beforehand. The commonly used method is DBSCAN (Density-Based Spatial Clustering of Applications with Noise).</p>
<ul>
<li>DBSCAN: Assigns data points to clusters based on their density and handles outliers as noise.</li>
</ul>
</section>
<section id="fuzzy-clustering" class="level3">
<h3 class="anchored" data-anchor-id="fuzzy-clustering">Fuzzy Clustering:</h3>
<p>Fuzzy clustering allows data points to belong to multiple clusters with varying degrees of membership. Each point has a membership value for each cluster.</p>
<ul>
<li>Fuzzy C-Means: Generalizes K-Means to assign membership values instead of strict assignments.</li>
</ul>
</section>
</section>
<section id="constraint-based-supervised-clustering" class="level2">
<h2 class="anchored" data-anchor-id="constraint-based-supervised-clustering">Constraint-based (Supervised Clustering):</h2>
<p>Constraint-based clustering incorporates predefined constraints during the clustering process. It ensures that certain pairs of points are either in the same or different clusters. It is useful in scenarios where prior knowledge or constraints on the relationships between data points are available.</p>
</section>
<section id="essential-clustering-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="essential-clustering-algorithms">Essential Clustering Algorithms</h2>
<section id="k-means" class="level3">
<h3 class="anchored" data-anchor-id="k-means">K-Means</h3>
<p>Ever wonder how computers make sense of heaps of data? Picture this: your data is like a bustling marketplace, and K-means clustering is the savvy guide helping to categorize similar items together while keeping distinct groups apart.</p>
<p>In simpler terms, clustering is a powerful tool in data science that helps find natural groups within a dataset. These groups, or clusters, share similarities among themselves but differ from other clusters. It’s like putting similar fruits together in a grocery store—you wouldn’t mix bananas with tomatoes, right?</p>
<p>Among various clustering methods, K-means takes the spotlight. It’s like the seasoned navigator guiding the exploration of data landscapes. This method is fantastic at revealing patterns and structures in the data. Think of clustering as a way to organize your data market. Hierarchical clustering, a method that groups things step by step, was the pioneer in this field. Over time, cluster analysis became a sophisticated tool in statistics and an unsupervised learning approach in machine learning.</p>
<p>In the world of statistics, clustering methods fall into two main categories: those based on probability models and those without specific assumptions. Probability model-based approaches assume that data points come from a mixture probability model, a bit like saying different items in the market belong to various categories.</p>
<p>In data science, partitional methods operate on the idea that a dataset can be represented by clear cluster prototypes, each with its specific characteristics. The key is figuring out how different a data point is from these prototypes. The K-means algorithm is a classic example of this approach, widely used and well-established. It works by grouping data points into clusters, helping to reveal patterns in the data. To get a feel for its effectiveness, let’s take a look at the popular “Iris” dataset, a common playground for data scientists using K-means clustering.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import necessary libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Iris dataset</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> load_iris()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> iris.data  <span class="co"># This is your "points"</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a KMeans instance with 3 clusters: model</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model to data</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>model.fit(data)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Determine the cluster labels: labels</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> model.predict(data)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the columns of data: xs and ys</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> data[:, <span class="dv">0</span>]</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> data[:, <span class="dv">1</span>]</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a scatter plot of xs and ys, using labels to define the colors</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.scatter(xs, ys, c<span class="op">=</span>labels, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign the cluster centers: centroids</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>centroids <span class="op">=</span> model.cluster_centers_</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign the columns of centroids: centroids_x, centroids_y</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>centroids_x <span class="op">=</span> centroids[:, <span class="dv">0</span>]</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>centroids_y <span class="op">=</span> centroids[:, <span class="dv">1</span>]</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a scatter plot of centroids_x and centroids_y</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>plt.scatter(centroids_x, centroids_y, marker<span class="op">=</span><span class="st">'D'</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-2-output-1.png" width="571" height="413"></p>
</div>
</div>
</section>
<section id="dbscan" class="level3">
<h3 class="anchored" data-anchor-id="dbscan">DBSCAN</h3>
<p>DBSCAN, short for Density-Based Spatial Clustering of Applications with Noise, is an unsupervised clustering algorithm that identifies clusters based on the density of data points. It distinguishes itself by forming clusters from regions with high density, effectively handling noise or areas with low data density.</p>
<p>The algorithm constructs nearest neighbor graphs, enabling the creation of clusters that can take on arbitrary shapes within datasets. This characteristic is in contrast to k-means clustering, which tends to generate clusters with spherical shapes. Notably, DBSCAN is resilient to noise or outliers in the data.</p>
<p>Advantages of DBSCAN: - Flexible Cluster Shapes: DBSCAN can find clusters of various shapes and sizes. - Robust to Outliers: It’s less sensitive to outliers compared to some other clustering algorithms. - No Need to Specify Cluster Count: Unlike some algorithms, you don’t need to specify the number of clusters beforehand.</p>
<p>The code snippet below uses DBSCAN to cluster data points into groups. Each point is assigned to a cluster, and the algorithm handles outliers as noise.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> DBSCAN</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Read the data</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"https://reneshbedre.github.io/assets/posts/tsne/tsne_scores.csv"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first 2 rows of the dataset</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head(<span class="dv">2</span>))</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the shape of the dataset</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.shape)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract features</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'t-SNE-1'</span>, <span class="st">'t-SNE-2'</span>]]</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform DBSCAN clustering</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>dbscan <span class="op">=</span> DBSCAN(eps<span class="op">=</span><span class="dv">5</span>, min_samples<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'cluster'</span>] <span class="op">=</span> dbscan.fit_predict(X)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the clusters</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">'t-SNE-1'</span>, y<span class="op">=</span><span class="st">'t-SNE-2'</span>, hue<span class="op">=</span><span class="st">'cluster'</span>, palette<span class="op">=</span><span class="st">'viridis'</span>, legend<span class="op">=</span><span class="st">'full'</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'DBSCAN Clustering Visualization'</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     t-SNE-1    t-SNE-2
0  10.846841 -16.712580
1  24.794334 -16.775398
(4406, 2)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="clustering_files/figure-html/cell-3-output-2.png" width="819" height="523"></p>
</div>
</div>
<p>The resulting visualization helps us to understand the natural groupings within the data, revealing patterns that may not be immediately apparent.</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>